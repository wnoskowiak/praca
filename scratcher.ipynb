{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory_path = '/workspace/outputDir'\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "combined_dataset = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"Combined dataset created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44272"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def getSize(imagePath):\n",
    "    image = Image.open(imagePath)\n",
    "\n",
    "    image = image.convert('L')\n",
    "\n",
    "    image_array = np.array(image)\n",
    "    \n",
    "    image_array = 255 - image_array\n",
    "    \n",
    "    dense_tensor = torch.tensor(image_array, dtype=torch.uint8)\n",
    "\n",
    "    # Find the indices of non-zero elements\n",
    "    non_zero_indices = torch.nonzero(dense_tensor, as_tuple=True)\n",
    "    \n",
    "    # Get the values of the non-zero elements\n",
    "    non_zero_values = dense_tensor[non_zero_indices]\n",
    "\n",
    "    # Create a sparse tensor\n",
    "    sparse_tensor = torch.sparse_coo_tensor(\n",
    "        indices=torch.stack(non_zero_indices),\n",
    "        values=non_zero_values,\n",
    "        size=dense_tensor.shape\n",
    "    )\n",
    "\n",
    "    sparse_tensor = sparse_tensor.coalesce()\n",
    "    \n",
    "    indices_memory = sparse_tensor.indices().numel() * sparse_tensor.indices().element_size()\n",
    "    values_memory = sparse_tensor.values().numel() * sparse_tensor.values().element_size()\n",
    "    sparse_tensor_memory_bytes = indices_memory + values_memory\n",
    "    sparse_tensor_memory_mb = sparse_tensor_memory_bytes / (1024 ** 2)\n",
    "    \n",
    "    return sparse_tensor, sparse_tensor_memory_mb\n",
    "\n",
    "    # print(image_array.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "combined_dataset['plane0_sparse_tensor'] = None\n",
    "combined_dataset['plane1_sparse_tensor'] = None\n",
    "combined_dataset['plane2_sparse_tensor'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m850.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2025.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: parsed_data_bnb_WithWire_04.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_04.csv, iteration: 100\n",
      "70.01553344726562\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_04.csv, iteration: 200\n",
      "140.7273759841919\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_04.csv, iteration: 300\n",
      "209.30729579925537\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_04.csv, iteration: 400\n",
      "280.94514560699463\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_04.csv, iteration: 500\n",
      "351.8641185760498\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_04.csv, iteration: 600\n",
      "426.20957946777344\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_04.csv, iteration: 700\n",
      "495.62755393981934\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_04.csv, iteration: 800\n",
      "565.2263946533203\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_04.csv, iteration: 900\n",
      "633.3639249801636\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_04.csv, iteration: 1000\n",
      "703.8807964324951\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_04.csv, iteration: 1100\n",
      "773.9233236312866\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_bnb_WithWire_04.pkl\n",
      "Processing file: parsed_data_bnb_WithWire_01.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_01.csv, iteration: 100\n",
      "75.23987007141113\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_01.csv, iteration: 200\n",
      "146.35973167419434\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_01.csv, iteration: 300\n",
      "218.06450653076172\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_01.csv, iteration: 400\n",
      "286.4492769241333\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_01.csv, iteration: 500\n",
      "358.01671600341797\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_01.csv, iteration: 600\n",
      "424.64778423309326\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_01.csv, iteration: 700\n",
      "494.4018268585205\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_01.csv, iteration: 800\n",
      "570.3129901885986\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_01.csv, iteration: 900\n",
      "639.9769887924194\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_01.csv, iteration: 1000\n",
      "711.2941074371338\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_01.csv, iteration: 1100\n",
      "779.2665948867798\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_01.csv, iteration: 1200\n",
      "845.9875936508179\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_bnb_WithWire_01.pkl\n",
      "Processing file: parsed_data_bnb_WithWire_05.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_05.csv, iteration: 100\n",
      "73.40594863891602\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_05.csv, iteration: 200\n",
      "143.0732707977295\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_05.csv, iteration: 300\n",
      "215.07476615905762\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_05.csv, iteration: 400\n",
      "284.9937381744385\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_05.csv, iteration: 500\n",
      "352.77201652526855\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_05.csv, iteration: 600\n",
      "429.9012222290039\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_05.csv, iteration: 700\n",
      "501.8084907531738\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_05.csv, iteration: 800\n",
      "571.4199285507202\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_05.csv, iteration: 900\n",
      "642.9700040817261\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_05.csv, iteration: 1000\n",
      "714.9557247161865\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_05.csv, iteration: 1100\n",
      "787.0856227874756\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_bnb_WithWire_05.pkl\n",
      "Processing file: parsed_data_bnb_WithWire_06.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_06.csv, iteration: 100\n",
      "73.60343265533447\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_06.csv, iteration: 200\n",
      "146.8913059234619\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_06.csv, iteration: 300\n",
      "217.37011051177979\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_06.csv, iteration: 400\n",
      "288.072322845459\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_06.csv, iteration: 500\n",
      "361.7893886566162\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_06.csv, iteration: 600\n",
      "432.30371475219727\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_06.csv, iteration: 700\n",
      "504.7359104156494\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_06.csv, iteration: 800\n",
      "569.8979024887085\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_06.csv, iteration: 900\n",
      "640.9944019317627\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_06.csv, iteration: 1000\n",
      "707.395058631897\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_06.csv, iteration: 1100\n",
      "774.1850738525391\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_06.csv, iteration: 1200\n",
      "848.7758617401123\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_bnb_WithWire_06.pkl\n",
      "Processing file: parsed_data_bnb_WithWire_03.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_03.csv, iteration: 100\n",
      "71.37520790100098\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_03.csv, iteration: 200\n",
      "142.4154176712036\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_03.csv, iteration: 300\n",
      "212.82006645202637\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_03.csv, iteration: 400\n",
      "286.822114944458\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_03.csv, iteration: 500\n",
      "361.61719608306885\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_03.csv, iteration: 600\n",
      "431.5665988922119\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_03.csv, iteration: 700\n",
      "502.48823070526123\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_03.csv, iteration: 800\n",
      "573.5072832107544\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_03.csv, iteration: 900\n",
      "646.8012847900391\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_11.csv, iteration: 1100\n",
      "784.1842241287231\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_11.csv, iteration: 1200\n",
      "855.6823225021362\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_bnb_WithWire_11.pkl\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 100\n",
      "67.63603019714355\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 200\n",
      "136.58291912078857\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 300\n",
      "206.9084186553955\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 400\n",
      "280.62708950042725\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 500\n",
      "353.17538261413574\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 600\n",
      "424.84878635406494\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 700\n",
      "493.7126188278198\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 800\n",
      "559.4955806732178\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 900\n",
      "631.0635871887207\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 1000\n",
      "700.0389776229858\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 1100\n",
      "773.184100151062\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 1200\n",
      "846.1431846618652\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 1300\n",
      "914.964054107666\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_12.csv, iteration: 1400\n",
      "987.3129501342773\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_bnb_WithWire_12.pkl\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 100\n",
      "69.55910396575928\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 200\n",
      "142.08649921417236\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 300\n",
      "213.49113273620605\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 400\n",
      "285.4068965911865\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 500\n",
      "360.66614055633545\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 600\n",
      "432.73313426971436\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 700\n",
      "503.4839029312134\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 800\n",
      "575.9092407226562\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 900\n",
      "651.2893323898315\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 1000\n",
      "726.3656673431396\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 1100\n",
      "800.4908494949341\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 1200\n",
      "871.0649995803833\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 1300\n",
      "941.89439868927\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_10.csv, iteration: 1400\n",
      "1010.4871587753296\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_bnb_WithWire_10.pkl\n",
      "Processing file: parsed_data_bnb_WithWire_13.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_13.csv, iteration: 100\n",
      "67.72881412506104\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_13.csv, iteration: 200\n",
      "140.2482328414917\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_13.csv, iteration: 300\n",
      "212.81163597106934\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_13.csv, iteration: 400\n",
      "280.3280019760132\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_13.csv, iteration: 500\n",
      "358.2726135253906\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_13.csv, iteration: 600\n",
      "424.0807046890259\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_13.csv, iteration: 700\n",
      "495.5752363204956\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_13.csv, iteration: 800\n",
      "566.0802726745605\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_13.csv, iteration: 900\n",
      "638.1291246414185\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_13.csv, iteration: 1000\n",
      "707.8360052108765\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_13.csv, iteration: 1100\n",
      "779.4789943695068\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_13.csv, iteration: 1200\n",
      "850.8372440338135\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_bnb_WithWire_13.pkl\n",
      "Processing file: parsed_data_bnb_WithWire_16.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_16.csv, iteration: 100\n",
      "71.17123889923096\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_16.csv, iteration: 200\n",
      "140.64971828460693\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_16.csv, iteration: 300\n",
      "211.18069458007812\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_16.csv, iteration: 400\n",
      "283.767897605896\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_16.csv, iteration: 500\n",
      "355.27392387390137\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_16.csv, iteration: 600\n",
      "423.3688802719116\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_16.csv, iteration: 700\n",
      "492.01185035705566\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_16.csv, iteration: 800\n",
      "567.6215267181396\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_16.csv, iteration: 900\n",
      "638.9373483657837\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_16.csv, iteration: 1000\n",
      "708.1129140853882\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_16.csv, iteration: 1100\n",
      "776.6309671401978\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_16.csv, iteration: 1200\n",
      "848.7124547958374\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_bnb_WithWire_16.pkl\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 100\n",
      "69.92561912536621\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 200\n",
      "140.94574165344238\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 300\n",
      "212.45728015899658\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 400\n",
      "281.7134704589844\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 500\n",
      "355.08002281188965\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 600\n",
      "423.62542629241943\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 700\n",
      "493.89098834991455\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 800\n",
      "566.8131246566772\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 900\n",
      "637.8653802871704\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 1000\n",
      "703.9437980651855\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 1100\n",
      "772.5183353424072\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 1200\n",
      "845.3268060684204\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_14.csv, iteration: 1300\n",
      "916.9087715148926\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_bnb_WithWire_14.pkl\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 100\n",
      "70.62131214141846\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 200\n",
      "144.10712337493896\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 300\n",
      "214.17358016967773\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 400\n",
      "282.01048278808594\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 500\n",
      "355.31160163879395\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 600\n",
      "424.33519172668457\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 700\n",
      "492.5840530395508\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 800\n",
      "564.06773853302\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 900\n",
      "632.0714025497437\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 1000\n",
      "699.6502838134766\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 1100\n",
      "769.9781179428101\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 1200\n",
      "842.9019727706909\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 1300\n",
      "909.5012807846069\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 1400\n",
      "976.7957792282104\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_17.csv, iteration: 1500\n",
      "1047.2828845977783\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_bnb_WithWire_17.pkl\n",
      "Processing file: parsed_data_bnb_WithWire_00.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_00.csv, iteration: 100\n",
      "69.59214496612549\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_00.csv, iteration: 200\n",
      "142.11553573608398\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_00.csv, iteration: 300\n",
      "210.51293563842773\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_00.csv, iteration: 400\n",
      "277.3159532546997\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_00.csv, iteration: 500\n",
      "351.33051776885986\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_00.csv, iteration: 600\n",
      "420.138822555542\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_00.csv, iteration: 700\n",
      "490.5385751724243\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_00.csv, iteration: 800\n",
      "562.1608448028564\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_00.csv, iteration: 900\n",
      "633.2527561187744\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_00.csv, iteration: 1000\n",
      "705.1094741821289\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_bnb_WithWire_00.pkl\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 100\n",
      "76.24817180633545\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 200\n",
      "151.83806896209717\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 300\n",
      "225.33548831939697\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 400\n",
      "303.3764181137085\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 500\n",
      "378.9593925476074\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 600\n",
      "456.2372341156006\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 700\n",
      "528.2450847625732\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 800\n",
      "604.6054954528809\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 900\n",
      "681.0415048599243\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 1000\n",
      "759.7532901763916\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 1100\n",
      "836.7902307510376\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 1200\n",
      "911.608738899231\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 1300\n",
      "987.958384513855\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_01.csv, iteration: 1400\n",
      "1060.3497247695923\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_nue_WithWire_01.pkl\n",
      "Processing file: parsed_data_nue_WithWire_00.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_00.csv, iteration: 100\n",
      "74.93831825256348\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_00.csv, iteration: 200\n",
      "146.34494590759277\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_00.csv, iteration: 300\n",
      "222.58587074279785\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_00.csv, iteration: 400\n",
      "296.26422119140625\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_00.csv, iteration: 500\n",
      "372.05037021636963\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_00.csv, iteration: 600\n",
      "448.664457321167\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_00.csv, iteration: 700\n",
      "522.3292865753174\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_00.csv, iteration: 800\n",
      "594.5563459396362\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_00.csv, iteration: 900\n",
      "675.500247001648\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_00.csv, iteration: 1000\n",
      "750.4133386611938\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_00.csv, iteration: 1100\n",
      "825.1010122299194\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_00.csv, iteration: 1200\n",
      "900.3402500152588\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_nue_WithWire_00.pkl\n",
      "Processing file: parsed_data_nue_WithWire_02.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_09.csv, iteration: 1100\n",
      "771.1121635437012\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_09.csv, iteration: 1200\n",
      "840.6028509140015\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_09.csv, iteration: 1300\n",
      "911.1350107192993\n",
      "====================\n",
      "Processing file: parsed_data_bnb_WithWire_09.csv, iteration: 1400\n",
      "984.3125419616699\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_bnb_WithWire_09.pkl\n",
      "Processing file: parsed_data_nue_WithWire_17.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_17.csv, iteration: 100\n",
      "74.90813064575195\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_17.csv, iteration: 200\n",
      "150.6377468109131\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_17.csv, iteration: 300\n",
      "229.0619878768921\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_17.csv, iteration: 400\n",
      "302.99369049072266\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_17.csv, iteration: 500\n",
      "380.4307222366333\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_17.csv, iteration: 600\n",
      "454.61409091949463\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_nue_WithWire_17.pkl\n",
      "Processing file: parsed_data_nue_WithWire_18.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_18.csv, iteration: 100\n",
      "70.77231502532959\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_18.csv, iteration: 200\n",
      "151.99774551391602\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_18.csv, iteration: 300\n",
      "225.32091331481934\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_18.csv, iteration: 400\n",
      "299.19585609436035\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_18.csv, iteration: 500\n",
      "373.90543270111084\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_18.csv, iteration: 600\n",
      "451.37623500823975\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_nue_WithWire_18.pkl\n",
      "Processing file: parsed_data_nue_WithWire_19.csv, iteration: 0\n",
      "0\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_19.csv, iteration: 100\n",
      "76.81264114379883\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_19.csv, iteration: 200\n",
      "150.9303331375122\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_19.csv, iteration: 300\n",
      "224.71258926391602\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_19.csv, iteration: 400\n",
      "301.00104904174805\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_19.csv, iteration: 500\n",
      "374.76540660858154\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_19.csv, iteration: 600\n",
      "450.43633365631104\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_19.csv, iteration: 700\n",
      "526.7609310150146\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_19.csv, iteration: 800\n",
      "602.1136560440063\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_19.csv, iteration: 900\n",
      "673.9971570968628\n",
      "====================\n",
      "Processing file: parsed_data_nue_WithWire_19.csv, iteration: 1000\n",
      "751.3827142715454\n",
      "====================\n",
      "Processed file pickled: /workspace/outputDir/processed_parsed_data_nue_WithWire_19.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "directory_path = '/workspace/outputDir'\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Add new columns for sparse tensors\n",
    "        df['plane0_sparse_tensor'] = None\n",
    "        df['plane1_sparse_tensor'] = None\n",
    "        df['plane2_sparse_tensor'] = None\n",
    "\n",
    "        sizeFull = 0\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Processing file: {filename}, iteration: {i}\")\n",
    "                print(sizeFull)\n",
    "                print(\"====================\")\n",
    "            for imName in ['plane1_file', 'plane2_file', 'plane0_file']:\n",
    "                full_file_path = os.path.join(directory_path, df.iloc[i][imName])\n",
    "                if os.path.exists(full_file_path):\n",
    "                    sparse_tensor, memory_mb = getSize(full_file_path)\n",
    "                    sizeFull += memory_mb\n",
    "                    df.at[i, f\"{imName.split('_')[0]}_sparse_tensor\"] = sparse_tensor\n",
    "                else:\n",
    "                    print(f\"Image not found: {full_file_path}\")\n",
    "\n",
    "        # Save the modified dataframe to a pickle file\n",
    "        output_file_path = os.path.join(directory_path, f\"processed_{filename.replace('.csv', '.pkl')}\")\n",
    "        with open(output_file_path, 'wb') as f:\n",
    "            pickle.dump(df, f)\n",
    "\n",
    "        print(f\"Processed file pickled: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: processed_parsed_data_bnb_WithWire_04.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_01.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_05.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_06.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_03.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_02.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_08.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_07.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_11.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_12.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_10.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_13.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_16.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_14.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_17.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_00.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_01.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_00.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_02.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_03.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_04.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_05.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_06.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_07.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_08.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_09.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_11.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_10.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_12.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_13.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_14.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_15.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_16.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_15.pkl\n",
      "Loading file: processed_parsed_data_bnb_WithWire_09.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_17.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_18.pkl\n",
      "Loading file: processed_parsed_data_nue_WithWire_19.pkl\n",
      "All pickled datasets loaded and combined successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the pickled files\n",
    "directory_path = '/workspace/outputDir'\n",
    "\n",
    "# List to store individual DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.pkl'):  # Check if the file is a pickle file\n",
    "        print(f\"Loading file: {filename}\")\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            df = pickle.load(f)  # Load the pickled DataFrame\n",
    "            dataframes.append(df)  # Append to the list\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "combined_dataset = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "print(\"All pickled datasets loaded and combined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(combined_dataset['plane2_sparse_tensor'])):\n",
    "    combined_dataset['plane2_sparse_tensor'][i].to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/outputDir/7017_1062_53144_1.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example usage\n",
    "file_name = combined_dataset.iloc[1300]['plane1_file']\n",
    "\n",
    "# Join the directory path with the file name\n",
    "full_file_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "print(full_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1067, 2400)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load the image using Pillow\n",
    "image = Image.open(full_file_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "image = image.convert('L')\n",
    "\n",
    "# Convert the grayscale image to a NumPy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "image_array = 255 - image_array\n",
    "\n",
    "\n",
    "\n",
    "print(image_array.shape)  # Print the shape of the grayscale image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "image_array = 255 - image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[   0,    0,    0,  ..., 1066, 1066, 1066],\n",
      "                       [1177, 1178, 1179,  ..., 1999, 2000, 2001]]),\n",
      "       values=tensor([255, 255, 255,  ...,  82,  16,  12]),\n",
      "       size=(1067, 2400), nnz=12017, dtype=torch.uint8, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Convert the NumPy array to a PyTorch tensor\n",
    "dense_tensor = torch.tensor(image_array, dtype=torch.uint8)\n",
    "\n",
    "# Find the indices of non-zero elements\n",
    "non_zero_indices = torch.nonzero(dense_tensor, as_tuple=True)\n",
    "\n",
    "# Get the values of the non-zero elements\n",
    "non_zero_values = dense_tensor[non_zero_indices]\n",
    "\n",
    "# Create a sparse tensor\n",
    "sparse_tensor = torch.sparse_coo_tensor(\n",
    "    indices=torch.stack(non_zero_indices),\n",
    "    values=non_zero_values,\n",
    "    size=dense_tensor.shape\n",
    ")\n",
    "\n",
    "\n",
    "print(sparse_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used by sparse_tensor: 0.19 MB\n",
      "Memory used by dense_tensor: 2.44 MB\n"
     ]
    }
   ],
   "source": [
    "# Coalesce the sparse tensor to ensure it is in a valid state\n",
    "sparse_tensor = sparse_tensor.coalesce()\n",
    "\n",
    "# Calculate memory usage of the sparse tensor\n",
    "indices_memory = sparse_tensor.indices().numel() * sparse_tensor.indices().element_size()\n",
    "values_memory = sparse_tensor.values().numel() * sparse_tensor.values().element_size()\n",
    "sparse_tensor_memory_bytes = indices_memory + values_memory\n",
    "sparse_tensor_memory_mb = sparse_tensor_memory_bytes / (1024 ** 2)\n",
    "\n",
    "# Calculate memory usage of the dense tensor\n",
    "dense_tensor_memory_bytes = dense_tensor.numel() * dense_tensor.element_size()\n",
    "dense_tensor_memory_mb = dense_tensor_memory_bytes / (1024 ** 2)\n",
    "\n",
    "# Print the comparison\n",
    "print(f\"Memory used by sparse_tensor: {sparse_tensor_memory_mb:.2f} MB\")\n",
    "print(f\"Memory used by dense_tensor: {dense_tensor_memory_mb:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
